{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940a04d9",
   "metadata": {},
   "source": [
    "## Regularization and Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c6ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17886a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\Linear Regression\\Modular\\Linear-Regression\\data\\Advertising.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c6f6311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper\n",
       "0  230.1   37.8       69.2\n",
       "1   44.5   39.3       45.1\n",
       "2   17.2   45.9       69.3\n",
       "3  151.5   41.3       58.5\n",
       "4  180.8   10.8       58.4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('sales',axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "543010ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0      22.1\n",
       "1      10.4\n",
       "2       9.3\n",
       "3      18.5\n",
       "4      12.9\n",
       "       ... \n",
       "195     7.6\n",
       "196     9.7\n",
       "197    12.8\n",
       "198    25.5\n",
       "199    13.4\n",
       "Name: sales, Length: 200, dtype: float64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['sales']\n",
    "y.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95a1b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2d852d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_conv = PolynomialFeatures(degree=3, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40428bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.30100000e+02, 3.78000000e+01, 6.92000000e+01, ...,\n",
       "        9.88757280e+04, 1.81010592e+05, 3.31373888e+05],\n",
       "       [4.45000000e+01, 3.93000000e+01, 4.51000000e+01, ...,\n",
       "        6.96564990e+04, 7.99365930e+04, 9.17338510e+04],\n",
       "       [1.72000000e+01, 4.59000000e+01, 6.93000000e+01, ...,\n",
       "        1.46001933e+05, 2.20434291e+05, 3.32812557e+05],\n",
       "       ...,\n",
       "       [1.77000000e+02, 9.30000000e+00, 6.40000000e+00, ...,\n",
       "        5.53536000e+02, 3.80928000e+02, 2.62144000e+02],\n",
       "       [2.83600000e+02, 4.20000000e+01, 6.62000000e+01, ...,\n",
       "        1.16776800e+05, 1.84062480e+05, 2.90117528e+05],\n",
       "       [2.32100000e+02, 8.60000000e+00, 8.70000000e+00, ...,\n",
       "        6.43452000e+02, 6.50934000e+02, 6.58503000e+02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_features = poly_conv.fit_transform(X)\n",
    "poly_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55641c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5fd6049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 19)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ff58410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    poly_features, y, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c878bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d38f1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e75b2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scalar.transform(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98258f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scalar.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbbdb82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.87800000e+02, 2.11000000e+01, 9.50000000e+00, 3.52688400e+04,\n",
       "       3.96258000e+03, 1.78410000e+03, 4.45210000e+02, 2.00450000e+02,\n",
       "       9.02500000e+01, 6.62348815e+06, 7.44172524e+05, 3.35053980e+05,\n",
       "       8.36104380e+04, 3.76445100e+04, 1.69489500e+04, 9.39393100e+03,\n",
       "       4.22949500e+03, 1.90427500e+03, 8.57375000e+02])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18178fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.455913  , -0.15469995, -0.98899258,  0.23144458,  0.12990319,\n",
       "       -0.57856073, -0.43655678, -0.66806654, -0.71668198,  0.02389419,\n",
       "        0.04869878, -0.45436665, -0.22089285, -0.47664217, -0.51504813,\n",
       "       -0.55818067, -0.60618091, -0.56426029, -0.5063835 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "893f57f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LinearRegression()\n",
    "final_model.fit(scaled_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "355e3f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.63372092, 19.05502371, 12.60912937, 17.2990722 ,  7.77663186,\n",
       "        6.82526502, 19.96783499, 17.13494321, 10.38316136, 19.70400344,\n",
       "        9.4100492 , 13.95881768, 11.61617522, 22.947182  , 18.90183411,\n",
       "        9.42091718, 12.35426982,  9.41694192,  8.7613977 , 21.27645807,\n",
       "        6.83781314, 19.30427609, 27.35825582, 24.30865659,  9.45328733,\n",
       "       11.27279575, 20.73582968,  9.63134669, 12.525551  ,  8.43317338,\n",
       "        8.79449102, 19.74446296, 10.90697498,  6.92971566, 18.07940374,\n",
       "        9.45452183, 10.73111886,  9.92794975,  7.07720069, 10.74715111,\n",
       "       12.15403331, 10.34977084, 11.58588333,  7.61811127, 11.90823723,\n",
       "       10.76007269,  5.14855579, 15.27095102, 12.95416074, 22.40476607,\n",
       "       10.72322437, 12.79300442, 14.91953663, 12.22762833, 11.13893795,\n",
       "        4.91876287, 24.97394881,  9.48559677, 17.27334217, 15.54639358,\n",
       "       15.02351556, 25.82928505,  8.73778123, 21.26133606, 11.96688674,\n",
       "       21.76326629])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = final_model.predict(scaled_X_test)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7332ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39321852865146933"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "MAE = mean_absolute_error(y_test, test_pred)\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f35a676d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31105771364312296"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = mean_squared_error(y_test, test_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c69e6d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5577254823325926"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE = np.sqrt(MSE)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdaebbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.15336483,   0.46253336,   0.30906374, -10.29471901,\n",
       "         4.99345277,  -1.52611765,  -1.29983091,   0.79105902,\n",
       "         0.25413361,   4.93455393,  -1.4879589 ,   1.36038495,\n",
       "         0.39332702,  -0.37778386,   0.01927523,   0.73076771,\n",
       "        -0.29499563,  -0.23108721,  -0.1775098 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69b34bb",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4622fd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Ridge in module sklearn.linear_model._ridge:\n",
      "\n",
      "class Ridge(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, _BaseRidge)\n",
      " |  Ridge(alpha=1.0, *, fit_intercept=True, normalize='deprecated', copy_X=True, max_iter=None, tol=0.001, solver='auto', positive=False, random_state=None)\n",
      " |  \n",
      " |  Linear least squares with l2 regularization.\n",
      " |  \n",
      " |  Minimizes the objective function::\n",
      " |  \n",
      " |  ||y - Xw||^2_2 + alpha * ||w||^2_2\n",
      " |  \n",
      " |  This model solves a regression model where the loss function is\n",
      " |  the linear least squares function and regularization is given by\n",
      " |  the l2-norm. Also known as Ridge Regression or Tikhonov regularization.\n",
      " |  This estimator has built-in support for multi-variate regression\n",
      " |  (i.e., when y is a 2d-array of shape (n_samples, n_targets)).\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <ridge_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  alpha : {float, ndarray of shape (n_targets,)}, default=1.0\n",
      " |      Regularization strength; must be a positive float. Regularization\n",
      " |      improves the conditioning of the problem and reduces the variance of\n",
      " |      the estimates. Larger values specify stronger regularization.\n",
      " |      Alpha corresponds to ``1 / (2C)`` in other linear models such as\n",
      " |      :class:`~sklearn.linear_model.LogisticRegression` or\n",
      " |      :class:`~sklearn.svm.LinearSVC`. If an array is passed, penalties are\n",
      " |      assumed to be specific to the targets. Hence they must correspond in\n",
      " |      number.\n",
      " |  \n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether to fit the intercept for this model. If set\n",
      " |      to false, no intercept will be used in calculations\n",
      " |      (i.e. ``X`` and ``y`` are expected to be centered).\n",
      " |  \n",
      " |  normalize : bool, default=False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`~sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      " |      on an estimator with ``normalize=False``.\n",
      " |  \n",
      " |      .. deprecated:: 1.0\n",
      " |          ``normalize`` was deprecated in version 1.0 and\n",
      " |          will be removed in 1.2.\n",
      " |  \n",
      " |  copy_X : bool, default=True\n",
      " |      If True, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  max_iter : int, default=None\n",
      " |      Maximum number of iterations for conjugate gradient solver.\n",
      " |      For 'sparse_cg' and 'lsqr' solvers, the default value is determined\n",
      " |      by scipy.sparse.linalg. For 'sag' solver, the default value is 1000.\n",
      " |      For 'lbfgs' solver, the default value is 15000.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Precision of the solution.\n",
      " |  \n",
      " |  solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg',             'sag', 'saga', 'lbfgs'}, default='auto'\n",
      " |      Solver to use in the computational routines:\n",
      " |  \n",
      " |      - 'auto' chooses the solver automatically based on the type of data.\n",
      " |  \n",
      " |      - 'svd' uses a Singular Value Decomposition of X to compute the Ridge\n",
      " |        coefficients. More stable for singular matrices than 'cholesky'.\n",
      " |  \n",
      " |      - 'cholesky' uses the standard scipy.linalg.solve function to\n",
      " |        obtain a closed-form solution.\n",
      " |  \n",
      " |      - 'sparse_cg' uses the conjugate gradient solver as found in\n",
      " |        scipy.sparse.linalg.cg. As an iterative algorithm, this solver is\n",
      " |        more appropriate than 'cholesky' for large-scale data\n",
      " |        (possibility to set `tol` and `max_iter`).\n",
      " |  \n",
      " |      - 'lsqr' uses the dedicated regularized least-squares routine\n",
      " |        scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative\n",
      " |        procedure.\n",
      " |  \n",
      " |      - 'sag' uses a Stochastic Average Gradient descent, and 'saga' uses\n",
      " |        its improved, unbiased version named SAGA. Both methods also use an\n",
      " |        iterative procedure, and are often faster than other solvers when\n",
      " |        both n_samples and n_features are large. Note that 'sag' and\n",
      " |        'saga' fast convergence is only guaranteed on features with\n",
      " |        approximately the same scale. You can preprocess the data with a\n",
      " |        scaler from sklearn.preprocessing.\n",
      " |  \n",
      " |      - 'lbfgs' uses L-BFGS-B algorithm implemented in\n",
      " |        `scipy.optimize.minimize`. It can be used only when `positive`\n",
      " |        is True.\n",
      " |  \n",
      " |      All last six solvers support both dense and sparse data. However, only\n",
      " |      'sag', 'sparse_cg', and 'lbfgs' support sparse input when `fit_intercept`\n",
      " |      is True.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |  \n",
      " |  positive : bool, default=False\n",
      " |      When set to ``True``, forces the coefficients to be positive.\n",
      " |      Only 'lbfgs' solver is supported in this case.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Used when ``solver`` == 'sag' or 'saga' to shuffle the data.\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         `random_state` to support Stochastic Average Gradient.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      " |      Weight vector(s).\n",
      " |  \n",
      " |  intercept_ : float or ndarray of shape (n_targets,)\n",
      " |      Independent term in decision function. Set to 0.0 if\n",
      " |      ``fit_intercept = False``.\n",
      " |  \n",
      " |  n_iter_ : None or ndarray of shape (n_targets,)\n",
      " |      Actual number of iterations for each target. Available only for\n",
      " |      sag and lsqr solvers. Other solvers will return None.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  RidgeClassifier : Ridge classifier.\n",
      " |  RidgeCV : Ridge regression with built-in cross validation.\n",
      " |  :class:`~sklearn.kernel_ridge.KernelRidge` : Kernel ridge regression\n",
      " |      combines ridge regression with the kernel trick.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.linear_model import Ridge\n",
      " |  >>> import numpy as np\n",
      " |  >>> n_samples, n_features = 10, 5\n",
      " |  >>> rng = np.random.RandomState(0)\n",
      " |  >>> y = rng.randn(n_samples)\n",
      " |  >>> X = rng.randn(n_samples, n_features)\n",
      " |  >>> clf = Ridge(alpha=1.0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Ridge()\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Ridge\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      _BaseRidge\n",
      " |      sklearn.linear_model._base.LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, alpha=1.0, *, fit_intercept=True, normalize='deprecated', copy_X=True, max_iter=None, tol=0.001, solver='auto', positive=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit Ridge regression model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training data.\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_targets)\n",
      " |          Target values.\n",
      " |      \n",
      " |      sample_weight : float or ndarray of shape (n_samples,), default=None\n",
      " |          Individual weights for each sample. If given a float, every sample\n",
      " |          will have the same weight.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "help(Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cf8acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "801001f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5182b179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.63279148, 19.05462723, 12.60618476, 17.29763322,  7.77320897,\n",
       "        6.82264123, 19.96882414, 17.13492079, 10.38766921, 19.70687286,\n",
       "        9.41019372, 13.95718451, 11.61803499, 22.94047684, 18.90385086,\n",
       "        9.41850361, 12.35481381,  9.42342298,  8.75937596, 21.27903888,\n",
       "        6.83505487, 19.30652475, 27.35163075, 24.30687645,  9.45442409,\n",
       "       11.2719876 , 20.73403682,  9.62704406, 12.52428176,  8.43335488,\n",
       "        8.79614975, 19.74742447, 10.90897814,  6.92624099, 18.08177712,\n",
       "        9.45488028, 10.72802559,  9.9307437 ,  7.07896816, 10.75097768,\n",
       "       12.15675602, 10.35020283, 11.58218428,  7.61577039, 11.90629962,\n",
       "       10.75690654,  5.1466492 , 15.27121368, 12.95218489, 22.40147835,\n",
       "       10.72471258, 12.79196439, 14.91849346, 12.22543309, 11.14012929,\n",
       "        4.92016005, 24.97311712,  9.48513086, 17.27145103, 15.5462033 ,\n",
       "       15.02450221, 25.82291424,  8.74600295, 21.25866034, 11.96525384,\n",
       "       21.76441096])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions =  ridge_model.predict(X_test)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a882db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3930126552894761"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "MAE = mean_absolute_error(y_test, test_predictions)\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "395f29ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5579455029352857"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "RMSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
